{"componentChunkName":"component---src-components-layout-js","path":"/aspetti-giuridici/","result":{"data":{"mdx":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Hello, world!\",\n  \"path\": \"/aspetti-giuridici\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"aspetti-giuridici\"\n  }, \"Aspetti Giuridici\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"600px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/IA/static/001da581559956f9382ef157265b0d61/b4294/img1.jpg\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"66.87116564417178%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAEEAgP/xAAVAQEBAAAAAAAAAAAAAAAAAAADAv/aAAwDAQACEAMQAAABlwuaFKIhP//EABgQAAMBAQAAAAAAAAAAAAAAAAECAxEA/9oACAEBAAEFApy1bTCjkc49NHf/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAXEAEBAQEAAAAAAAAAAAAAAAAREAAh/9oACAEBAAY/AjcKE//EABkQAAMBAQEAAAAAAAAAAAAAAAABEUEQgf/aAAgBAQABPyGw0aKD0QxCMHZHP//aAAwDAQACAAMAAAAQDO//xAAWEQEBAQAAAAAAAAAAAAAAAAARARD/2gAIAQMBAT8Qi5//xAAWEQEBAQAAAAAAAAAAAAAAAAARARD/2gAIAQIBAT8QoZ//xAAaEAEBAAMBAQAAAAAAAAAAAAABEQAhMUFR/9oACAEBAAE/EKZQXcwKEMTR5ye/cG8cIscvcUyFErZPmLvP/9k=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"img1\",\n    \"title\": \"img1\",\n    \"src\": \"/IA/static/001da581559956f9382ef157265b0d61/b4294/img1.jpg\",\n    \"srcSet\": [\"/IA/static/001da581559956f9382ef157265b0d61/d2f63/img1.jpg 163w\", \"/IA/static/001da581559956f9382ef157265b0d61/c989d/img1.jpg 325w\", \"/IA/static/001da581559956f9382ef157265b0d61/b4294/img1.jpg 600w\"],\n    \"sizes\": \"(max-width: 600px) 100vw, 600px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"p\", null, \"L\\u2019intelligenza artificiale rappresenta, potenzialmente, una grande opportunit\\xE0 per l\\u2019umanit\\xE0: tale tecnologia \\xE8 e sar\\xE0 sempre pi\\xF9 presente nella nostra vita quotidiana e, in un futuro non troppo remoto, diventer\\xE0, probabilmente, qualcosa con cui sar\\xE0 normale convivere. Prima che questo accada, per\\xF2, bisogna risolvere alcuni punti aperti, fondamentali per l\\u2019espansione su larga scala dell\\u2019IA.\"), mdx(\"p\", null, \"Uno di questi \\xE8 senza dubbio l\\u2019aspetto giuridico: un sistema di intelligenza artificiale, in quanto tale, non ha personalit\\xE0 giuridica, e non pu\\xF2 quindi assumersi la responsabilit\\xE0 diretta di un atto da esso stesso provocato. Ci\\xF2 non sarebbe un problema se tali sistemi svolgessero solamente azioni per cui sono stati programmati: in tal caso, nell\\u2019eventualit\\xE0 di danni causati da essi, la responsabilit\\xE0 ricadrebbe necessariamente sul produttore, sul programmatore o sull\\u2019utilizzatore, a seconda dei casi. Ma la realt\\xE0 \\xE8 ben diversa. Le macchine dotate di intelligenza artificiale sono, e saranno sempre di pi\\xF9, fornite di un sistema chiamato \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Machine learning\"), \", il quale, come approfonditamente analizzato nella sezione riguardante gli aspetti tecnici, si presenta come un \\u201Csoftware di apprendimento\\u201D che permette loro di assimilare o migliorare talune performance, basandosi sui dati ottenuti e utilizzati. Come \\xE8 facilmente constatabile, tale sistema porter\\xE0 le macchine ad essere sempre pi\\xF9 svincolate dalla programmazione umana, ad agire con crescente autonomia e, di conseguenza, ad avere una maggiore imprevedibilit\\xE0.\"), mdx(\"p\", null, \"Come risolvere questo problema?\"), mdx(\"p\", null, \"Sono presenti diverse linee di pensiero: analizziamole separatamente.\"), mdx(\"h1\", {\n    \"id\": \"intelligenza-artificiale-forte\"\n  }, \"Intelligenza Artificiale Forte\"), mdx(\"p\", null, \"Considerando il crescente grado indipendenza dei sistemi ad IA, il quale d\\xE0 loro la possibilit\\xE0 di reagire a stimoli provenienti dall\\u2019esterno e di interagire con parti terze, la prima e pi\\xF9 innovativa teoria si basa sulla convinzione che, nel XXI secolo, alle porte di una \\u201Cquarta rivoluzione industriale\\u201D, sia necessaria anche una rivoluzione giuridica. I sostenitori di tale tesi (tra i quali \\xE8 possibile annoverare \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Alan Turing\"), \"), compresa nella corrente di pensiero dell\\u2019\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Intelligenza Artificiale Forte,\"), \" ritengono che sia auspicabile riconoscere ai sistemi di intelligenza artificiale una propria soggettivit\\xE0. Tale decisione porterebbe i \\u201Csoggetti\\u201D dotati di IA, oltre che ad avere una personalit\\xE0 legale, anche a diventare titolari di un\\u2019identit\\xE0 tramite un numero identificativo e, secondo alcuni, a ricevere il riconoscimento di un patrimonio proprio.\"), mdx(\"p\", null, \"Ai possibili vantaggi di questa concezione, tra cui, soprattutto, la tutela e regolazione delle conseguenza legali delle sue azioni, si contrappongono per\\xF2 diversi problemi: in primis, non \\xE8 assicurato che la tutela legale della vittima sia effettivamente migliorata dall\\u2019attribuzione di una personalit\\xE0 giuridica ad un automa, ad esempio in ambito di compensazione della vittima, la quale risulterebbe realmente garantita solo dalla copertura del robot da parte di un\\u2019\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"assicurazione\"), \". Inoltre, riconoscendo loro una personalit\\xE0 giuridica, e diventando quindi soggetti di diritto, si rischierebbe la \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"deresponsabilizzazione\"), \" dei costruttori e degli utilizzatori.\"), mdx(\"h1\", {\n    \"id\": \"intelligenza-artificiale-debole\"\n  }, \"Intelligenza Artificiale Debole\"), mdx(\"p\", null, \"La corrente di pensiero dell\\u2019\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"intelligenza artificiale debole\"), \" (tra i cui sostenitori ricordiamo il filosofo \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"John Searle\"), \") ha una concezione pi\\xF9 minimalista della questione. I fautori di tale corrente reputano che un calcolatore che abbia superato il \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Test di Turing\"), \" non sia un vero e proprio \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"essere pensante\"), \", ma soltanto uno strumento di controllo dei ragionamenti umani, in grado di simularli ma non di comprendere il significato degli atti che compie.\"), mdx(\"p\", null, \"Per questo motivo, tale filosofia ritiene che non sia possibile travalicare il limite interposto tra esseri umani e calcolatori, attribuendo a questi ultimi la qualifica di soggetti. Secondo l\\u2019opinione di alcuni, pur mantenendo lo status di oggetto, sarebbe possibile creare un \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"regime legale speciale\"), \" adattabile a qualsiasi dispositivo dotato di intelligenza artificiale, assimilabile a quello attualmente applicato agli animali, che fungerebbe da modello al fine di crearne uno apposito per i calcolatori.\"), mdx(\"p\", null, \"In tal caso, ad esempio, il proprietario o l\\u2019utilizzatore del dispositivo risulterebbe responsabile dei danni cagionati da esso nell\\u2019ipotesi di una perdita di controllo; al contempo, il dispositivo godrebbe di alcuni diritti, nel caso in cui esso dovesse subire attacchi alla sua integrit\\xE0 o danni provocati da soggetti terzi. In quanto meno radicale, l\\u2019adozione di un simile regime risulta perci\\xF2 rilevante e degna di nota.\"), mdx(\"h1\", {\n    \"id\": \"altre-possibili-soluzioni\"\n  }, \"Altre Possibili Soluzioni\"), mdx(\"p\", null, \"Altre proposte, in via di sviluppo in Paesi come la \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Corea del Sud\"), \" e gli \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Stati Uniti\"), \", comprendono l\\u2019introduzione di \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"carte dei diritti dei robot\"), \": esse, oltre a concedere, appunto, diritti a tali dispositivi, hanno il principale scopo di definire il loro campo d\\u2019applicazione, arginandolo tramite limiti \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"etici\"), \". Ci\\xF2 ha lo scopo di evitare utilizzi deontologicamente scorretti dei dispositivi, ad esempio nel contesto dei \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"robot killer\"), \". Tale provvedimento fa fede a quanto esposto da \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Isaac Asimov\"), \" nelle celebri \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"leggi della robotica\"), \", le quali asseriscono che un robot non deve metterne a rischio l\\u2019incolumit\\xE0 umana; al fine di evitare un uso deviato e distorto dei dispositivi contribuiscono, da una parte, le barriere fisiche e i sistemi di sicurezza e, dall\\u2019altra, i limiti derivanti da un chiaro quadro \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"etico\"), \" e \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"giuridico\"), \". A tal proposito, \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Ron Arkin\"), \"; professore della School of Computing al Georgia Institute of Technology, suggerisce l\\u2019introduzione di un \\u201C\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"agente morale artificiale\\u201D\"), \", tramite l\\u2019introduzione nella macchina di una serie di regole che costituiscano una \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"pseudo-coscienza\"), \" della stessa, in modo da permettere la scelta della modalit\\xE0 d\\u2019azione in base, anche, a fattori di tipo etico.\"), mdx(\"h1\", {\n    \"id\": \"le-proposte-dellunione-europea\"\n  }, \"Le Proposte dell'Unione Europea\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"650px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/IA/static/180280771261511dc051803f62fd1721/29d31/img2.jpg\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"66.87116564417178%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAUBAgT/xAAVAQEBAAAAAAAAAAAAAAAAAAABAP/aAAwDAQACEAMQAAAB2QosjQWk/wD/xAAaEAACAgMAAAAAAAAAAAAAAAAAAQITAxIh/9oACAEBAAEFArkXxN0xdEmzHCyP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFREBAQAAAAAAAAAAAAAAAAAAABH/2gAIAQIBAT8BiP/EABwQAAIBBQEAAAAAAAAAAAAAAAABMQIREjKRYf/aAAgBAQAGPwLZcJXDagfhJldo/8QAGxAAAgIDAQAAAAAAAAAAAAAAAREAITFRYXH/2gAIAQEAAT8hVmnqUVuyEN1XoMchBRq1mOONTz1Qn//aAAwDAQACAAMAAAAQlM//xAAVEQEBAAAAAAAAAAAAAAAAAAAQEf/aAAgBAwEBPxCn/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxAP/8QAHxABAQABBAIDAAAAAAAAAAAAAREAMUFRkSFhccHR/9oACAEBAAE/EF84pP1yqgLV+5kb4yvAWaloe3iJ3iySRLFXtm3GQwGom6bru5//2Q==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"img2\",\n    \"title\": \"img2\",\n    \"src\": \"/IA/static/180280771261511dc051803f62fd1721/6aca1/img2.jpg\",\n    \"srcSet\": [\"/IA/static/180280771261511dc051803f62fd1721/d2f63/img2.jpg 163w\", \"/IA/static/180280771261511dc051803f62fd1721/c989d/img2.jpg 325w\", \"/IA/static/180280771261511dc051803f62fd1721/6aca1/img2.jpg 650w\", \"/IA/static/180280771261511dc051803f62fd1721/29d31/img2.jpg 700w\"],\n    \"sizes\": \"(max-width: 650px) 100vw, 650px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"p\", null, \"Considerando quanto appena esposto, appare chiaro che sia fondamentale definire un quadro normativo completo, che comprenda \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"principi etici\"), \" e \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"obblighi giuridici\"), \" relativi allo sviluppo, la diffusione e l\\u2019utilizzo dell\\u2019intelligenza artificiale, della robotica e delle tecnologie correlate, soprattutto di quelle ad alto rischio. Tutto ci\\xF2 deve essere necessariamente basato sul diritto vigente nell\\u2019Unione Europea e sulla dichiarazione universale dei diritti umani e deve, da una parte, consentire l\\u2019introduzione, lo sviluppo e la diffusione di tecnologie innovative e, al contempo, garantire la protezione dei valori dell\\u2019Unione e dell\\u2019incolumit\\xE0 delle persone.\"), mdx(\"p\", null, \"Per questo motivo, il 20 Ottobre 2020, il Parlamento Europeo ha approvato tre proposte in merito a \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"propriet\\xE0 intellettuale\"), \", \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"aspetti etici\"), \" e \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"responsabilit\\xE0 civile\"), \" nell\\u2019ambito di dispositivi dotati di IA.\"), mdx(\"h2\", {\n    \"id\": \"responsabilità-civile\"\n  }, \"Responsabilit\\xE0 civile\"), mdx(\"p\", null, \"In merito a ci\\xF2, il principio cardine attorno al quale ruota la proposta sta nell\\u2019equilibrio tra la garanzia del diritto di una persona che abbia subito \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"danno o pregiudizio\"), \" a richiedere un risarcimento dalla controparte di cui sia stata dimostrata la possibilit\\xE0 e l\\u2019incentivo a persone fisiche e giuridiche ad attivarsi sin dall\\u2019inizio per evitare di causare danni o pregiudizi avvalendosi di sistemi di IA.\"), mdx(\"p\", null, \"Il Parlamento Europeo ritiene inoltre che ogni quadro giuridico in materia di responsabilit\\xE0 civile debba infondere fiducia nella sicurezza e nell\\u2019affidabilit\\xE0 di prodotti e servizi, compresa la tecnologia digitale: secondo esso occorre, dunque, trovare un punto di stabilit\\xE0 tra un\\u2019efficace e garantita tutela delle vittime ed una sufficiente libert\\xE0 d\\u2019azione delle imprese produttrici e sviluppatrici di tali prodotti.\"), mdx(\"h2\", {\n    \"id\": \"obbligo-di-assicurazione\"\n  }, \"Obbligo di assicurazione\"), mdx(\"p\", null, \"Al fine di perseguire tali obiettivi, la proposta impone agli operatori, produttori ed utilizzatori di sistemi di IA di attivare un\\u2019apposita \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"polizza assicurativa\"), \" per la \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"responsabilit\\xE0 civile\"), \", adeguata agli importi e all\\u2019entit\\xE0 del risarcimento, anch\\u2019essi stabiliti dal regolamento, il quale trover\\xE0 applicazione, all\\u2019interno del territorio dell\\u2019Unione, laddove un\\u2019attivit\\xE0, un dispositivo o un processo virtuale o fisico guidato da un sistema di IA abbia arrecato un danno o un pregiudizio alla vita, alla salute, all\\u2019integrit\\xE0 fisica di una persona fisica, al patrimonio di una persona fisica o giuridica o abbia arrecato un danno immateriale rilevante risultante in una perdita economica verificabile. Inoltre, \\xE8 presente una precisa differenziazione tra i sistemi di IA \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"ad alto rischio\"), \", individuati da un apposito\"), mdx(\"p\", null, \"elenco di definizioni, per i quali la responsabilit\\xE0 \\xE8 oggettiva in caso di danni o pregiudizi arrecati, rispetto agli altri sistemi di IA dove la responsabilit\\xE0 assume il grado di colpa, sino a potere essere esclusa in caso di dimostrazione della non imputabilit\\xE0 in presenza di alcuni motivi individuati.\"), mdx(\"h2\", {\n    \"id\": \"definizioni\"\n  }, \"Definizioni\"), mdx(\"p\", null, \"La proposta contiene una serie di definizioni utili al fine di raggiungere gli obiettivi preposti, tra le quali:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Sistema di intelligenza artificiale\"), \":\", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \" esso \\xE8 definito come un\"), \" sistema basato su un software o integrato in dispositivi hardware che mostra un comportamento che simula l\\u2019intelligenza, tra l\\u2019altro raccogliendo e trattando dati, analizzando e interpretando il proprio ambiente e intraprendendo azioni, con un certo grado di autonomia, per raggiungere obiettivi specifici. Tale sistema diviene \\u201Cautonomo\\u201D quando \\xE8 in grado di operare interpretando determinati dati forniti e utilizzando una serie di istruzioni predeterminate, senza essere limitato a tali istruzioni, nonostante il comportamento del sistema sia legato e volto al conseguimento dell\\u2019obiettivo impartito e ad altre scelte operate dallo sviluppatore in sede di progettazione.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Sistema di intelligenza artificiale ad alto rischio\"), \": in un apposito elenco, allegato al regolamento, sono individuati tali sistemi (come, ad esempio, gli aeromobili senza equipaggio, i veicoli con livelli di automazione, i sistemi autonomi di gestione del traffico e i robot autonomi) i quali sono contraddistinti da un potenziale significativo di causare danni o pregiudizi a una o pi\\xF9 persone in modo casuale e che va oltre quanto ci si possa ragionevolmente aspettare. Un aspetto da rimarcare \\xE8 la riconducibilit\\xE0 della responsabilit\\xE0 civile a tutti gli operatori, siano essi di \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"front-end\"), \", ossia le persone fisiche o giuridiche che esercitano un certo grado di controllo su un rischio connesso all\\u2019operativit\\xE0 e al funzionamento del sistema di IA e che beneficiano del suo funzionamento, che di \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"back-end\"), \", ovvero persone fisiche o giuridiche, le quali, su base continuativa, definiscono le caratteristiche della tecnologia e forniscono i dati e il servizio di supporto di back-end essenziale, esercitando perci\\xF2 anche un elevato grado di controllo su un rischio connesso all\\u2019operativit\\xE0 e al funzionamento del sistema di IA. Gli operatori non sono invece considerati responsabili se risulta dimostrato che il danno o il pregiudizio sia stato dovuto a cause di forza maggiore. Quanto alla copertura assicurativa, l\\u2019operatore di front-end si assicura che le operazioni del sistema siano coperte da un\\u2019assicurazione a copertura della responsabilit\\xE0 civile adeguata agli importi e all\\u2019entit\\xE0 del risarcimento previsti. L\\u2019operatore di back-end si assicura invece che i suoi servizi siano coperti da un\\u2019assicurazione della responsabilit\\xE0 civile prodotti o imprese anch\\u2019essa adeguata agli importi e all\\u2019entit\\xE0 del risarcimento.\")), mdx(\"h2\", {\n    \"id\": \"altri-sistemi-di-ia\"\n  }, \"Altri sistemi di IA\"), mdx(\"p\", null, \"Un sistema di intelligenza artificiale che non sia considerato ad alto rischio, \\xE8 soggetto a un regime di responsabilit\\xE0 per colpa in caso di eventuali danni o pregiudizi causati da un\\u2019attivit\\xE0, dispositivo o processo fisico o virtuale guidato dal sistema stesso. L\\u2019operatore non risulta responsabile qualora riesca a dimostrare che:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"il sistema di IA si sia attivato senza che l\\u2019operatore ne fosse a conoscenza, nonostante fossero state adottate tutte le misure ragionevoli e necessarie per evitare tale attivazione al di fuori del controllo dell\\u2019operatore stesso;\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"sia stata rispettata la dovuta diligenza con lo svolgimento delle seguenti operazioni:\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"selezionamento di un sistema di IA idoneo al compito e alle competenze;\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"messa debitamente in funzione del sistema di IA;\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"monitoraggio delle attivit\\xE0;\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"mantenimento dell\\u2019affidabilit\\xE0 operativa mediante la periodica installazione di tutti gli aggiornamenti disponibili;\")))), mdx(\"p\", null, \"L\\u2019operatore non pu\\xF2 svincolarsi dalla responsabilit\\xE0 sostenendo che il danno o il pregiudizio sia stato cagionato da un\\u2019attivit\\xE0, dispositivo o processo autonomo guidato dal suo sistema di IA ma, anche in questo caso, pu\\xF2 farlo in caso dimostri che il danno sia stato dovuto a cause di forza maggiore.\"), mdx(\"p\", null, \"Qualora il danno o il pregiudizio sia stato causato da un terzo che abbia interferito con il sistema di IA attraverso la modifica del suo funzionamento o dei suoi effetti, l\\u2019operatore \\xE8 comunque tenuto a corrispondere un risarcimento se tale terzo non \\xE8 rintracciabile o \\xE8 insolvibile.\"), mdx(\"h2\", {\n    \"id\": \"risarcimento\"\n  }, \"Risarcimento\"), mdx(\"p\", null, \"Un operatore di un sistema IA, che sia stato riconosciuto colpevole di danni o pregiudizi, \\xE8 tenuto a risarcire:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"fino a un importo massimo di due milioni di euro in caso di morte o danni alla salute o all\\u2019integrit\\xE0 fisica di una persona interessata in conseguenza della messa in funzione di un sistema di IA ad alto rischio;\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"fino a un importo massimo di un milione di euro in caso di danni immateriali rilevanti che risultino in una perdita economica verificabile o di danni al patrimonio in conseguenza di un\\u2019unica messa in funzione di un unico sistema di IA ad alto rischio.\")), mdx(\"h2\", {\n    \"id\": \"prescrizione\"\n  }, \"Prescrizione\"), mdx(\"p\", null, \"Le azioni per responsabilit\\xE0 civile in merito a danni o pregiudizi alla \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"vita\"), \" o all\\u2019\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"incolumit\\xE0 fisica\"), \" sono soggette a un termine di prescrizione di 30 anni.\"), mdx(\"p\", null, \"Le azioni per responsabilit\\xE0 civile in quanto a rilevanti danni al \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"patrimonio\"), \" o \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"immateriali\"), \" sono soggetti a un termine di prescrizione speciale di:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"30 anni, in caso di sistemi di IA ad alto rischio;\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"10 anni, in tutti gli altri casi.\")), mdx(\"h1\", {\n    \"id\": \"la-nuova-proposta-della-commisione-europea\"\n  }, \"La Nuova Proposta della Commisione Europea\"), mdx(\"p\", null, \"Il 21 aprile 2021 la Commissione Europea ha pubblicato un\\u2019innovativa e ambiziosa proposta di \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Regolamento sull\\u2019Intelligenza Artificiale\"), \". Esso si focalizza principalmente su determinati utilizzi dei sistemi ad IA ad \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"alto rischio\"), \". Anche in questo caso, l\\u2019obiettivo della proposta \\xE8 duplice: innanzitutto, la tutela dei \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"diritti fondamentali\"), \" e dei \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"valori europei\"), \" e, in secondo luogo, la garanzia di una regolamentazione \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"adeguata\"), \" e \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"proporzionata\"), \",\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \" che non limiti lo sviluppo tecnologico, ma lo promuova, sviluppando fiducia in questa tecnologia e garantendo all\\u2019UE una posizione di \"), \"leadership tecnologica.\", \"*\", \"*\"), mdx(\"h2\", {\n    \"id\": \"ambiti-di-applicazione\"\n  }, \"Ambiti di applicazione\"), mdx(\"p\", null, \"Il regolamento viene applicato all\\u2019immissione sul mercato, alla messa in servizio e all\\u2019uso di sistemi di IA, e divide gli usi in base al grado di \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"rischio\"), \": basso, medio o elevato. Esso non \\xE8 applicato ai sistemi di IA utilizzati esclusivamente a scopo \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"militare\"), \"; non si applica inoltre alle \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"autorit\\xE0 pubbliche\"), \" di Paesi terzi n\\xE9 alle \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"organizzazioni internazionali\"), \", solo qualora esse non utilizzino sistemi di IA nell\\u2019ambito di programmi di cooperazione giudiziaria o investigativa con l\\u2019Ue o con uno Stato Membro.. In merito all\\u2019ambito di applicazione \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"territoriale\"), \", il Regolamento si applica sia agli operatori europei, che ai fornitori o utenti di sistemi di IA stabiliti al di fuori dell\\u2019Ue, nel caso in cui l\\u2019\\u201Coutput\\u201D dei sistemi venga utilizzato all\\u2019intero dell\\u2019UE.\"), mdx(\"h2\", {\n    \"id\": \"usi-vietati-dellia\"\n  }, \"Usi vietati dell\\u2019IA\"), mdx(\"p\", null, \"Il Regolamento vieta in termini assoluti:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"La vendita e l\\u2019uso di sistemi di IA che utilizzano tecniche \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"subliminali\"), \" per distorcere in maniera sostanziale il comportamento di una persona, potendo cos\\xEC causare, danni fisici o psichici a quella persona o ad altri;\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"La vendita e l\\u2019uso di sistemi di IA che sfruttano una \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"vulnerabilit\\xE0\"), \" legata all\\u2019et\\xE0 o ad una disabilit\\xE0 di uno specifico gruppo di persone al fine di distorcere in maniera sostanziale il comportamento di una persona appartenente al gruppo, potendo in questo modo causare danni fisici o psicologici a quella persona o a terzi;\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"L\\u2019uso di sistemi di \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"credito sociale\"), \", il quale \\xE8 utilizzato per classificare la reputazione dei cittadini, da parte delle autorit\\xE0 pubbliche o da parte di chi agisce per conto delle stesse;\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"L\\u2019utilizzo in tempo reale di sistemi di \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"identificazione biometrica da remoto\"), \" (come i sistemi di riconoscimento facciale) in luoghi accessibili al pubblico per finalit\\xE0 di repressione dei reati. Il Regolamento per\\xF2 prevede svariate eccezioni a questo divieto e lascia in parte liberi gli Stati Membri di consentire e regolamentare l\\u2019uso di questo tipo di sistemi di IA.\")), mdx(\"h2\", {\n    \"id\": \"regolamentazione-dei-sistemi-di-ia-ad-alto-rischio\"\n  }, \"Regolamentazione dei sistemi di IA ad alto rischio\"), mdx(\"p\", null, \"Il Regolamento qualifica come \\u201Csistemi di IA ad alto rischio\\u201D una serie di tecnologie che \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"creano rischi elevati per la salute, la sicurezza o i diritti fondamentali delle persone\"), \", e ne prevede due principali categorie:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"I sistemi destinati ad essere utilizzati come componenti di \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"sicurezza\"), \" di altri prodotti prodotti come, ad esempio, i dispositivi medici;\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Una serie di sistemi di IA specificamente elencati in un allegato del Regolamento, che potr\\xE0 essere integrato nel corso del tempo seguendo una seie di criteri fissati, tra cui i sistemi di IA da utilizzare per la selezione del personale, per valutare la solvibilit\\xE0 delle persone e i sistemi di polizia predittiva.\")), mdx(\"h2\", {\n    \"id\": \"regole-per-sistemi-ad-alto-rischio\"\n  }, \"Regole per sistemi ad alto rischio\"), mdx(\"p\", null, \"Tra le regole presenti per tali sistemi, \\xE8 possibile citare, in particolare:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"L\\u2019obbligo di creare e mantenere attivo un sistema di \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"risk management\"), \" (gestione del rischio);\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"L\\u2019obbligo di assicurarsi che essi vengano sviluppati seguendo specifici criteri qualitativi per quanto riguarda i dati ed i modelli utilizzati, documentando in maniera adeguata come \\xE8 avvenuto lo sviluppo di un determinato sistema di IA ed il funzionamento dello stesso;\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"L\\u2019obbligo di assicurarsi che tali sistemi possano essere sottoposti a supervisione da parti di persone fisiche (\", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"human oversight\"), \");\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"L\\u2019obbligo di garantire la loro \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"attendibilit\\xE0\"), \", \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"accuratezza\"), \" e \", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"sicurezza\"), \".\")), mdx(\"p\", null, \"La verifica del rispetto dei requisiti di cui sopra avverr\\xE0 attraverso \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"\\u201Cprocedure di valutazione della conformit\\xE0\\u201D\"), \", secondo modalit\\xE0 identiche o analoghe a quelle gi\\xE0 previste per altri prodotti regolamentati a livello europeo. Questo sistema di \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"conformity assessment\"), \" sar\\xE0 facilitato dall\\u2019adozione di appositi standard di riferimento da parte degli enti di normazione.\"), mdx(\"h2\", {\n    \"id\": \"regulatory-sandboxes\"\n  }, \"Regulatory sandboxes\"), mdx(\"p\", null, \"Il Regolamento introduce la possibilit\\xE0 di creare specifici \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"regulatory sandboxes\"), \", ossia strumenti giuridici che permettono a determinate societ\\xE0 di accedere ad un ambiente di sperimentazione al fine di verificare l\\u2019impatto del proprio prodotto sul mercato. Tale norma \\xE8 stata introdotta allo scopo, come precedentemente detto, di incentivare lo \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"sviluppo tecnologico\"), \" e la fiducia nello stesso.\"), mdx(\"h2\", {\n    \"id\": \"monitoraggio-dei-sistemi-di-ia\"\n  }, \"Monitoraggio dei sistemi di IA\"), mdx(\"p\", null, \"In merito agli aspetti istituzionali, il Regolamento prevede la fondazione di un \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Comitato europeo per l\\u2019intelligenza artificiale\"), \", ossia un organo con il compito specifico di sorvegliare la corretta \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"applicazione del Regolamento\"), \" nei vari Stati Membri e di elaborare \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"linee guida\"), \" in materia.\"), mdx(\"p\", null, \"Inoltre, per quanto riguarda il monitoraggio successivo all\\u2019immissione in commercio, i fornitori sono tenuti ad implementare \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"sistemi volti a\"), \" \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"monitorare\"), \" l\\u2019utilizzo dei dispositivi che immettono sul mercato, per verificare se gli stessi rimangono \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"conformi al Regolamento\"), \" nel corso del proprio ciclo di vita. Sono inoltre tenuti a segnalare alle autorit\\xE0 competenti eventuali malfunzionamenti ed incidenti che dovessero riscontrarsi attraverso tale attivit\\xE0 di monitoraggio.\"), mdx(\"h2\", {\n    \"id\": \"sanzioni\"\n  }, \"Sanzioni\"), mdx(\"p\", null, \"Il Regolamento prevede che le \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"autorit\\xE0 competenti\"), \", individuate da ciascuno Stato Membro, potranno prescrivere sanzioni amministrative fino a 30.000.000\\u20AC in caso di violazioni del Regolamento.\"), mdx(\"h2\", {\n    \"id\": \"conclusioni\"\n  }, \"Conclusioni\"), mdx(\"p\", null, \"Il Regolamento risulta particolarmente innovativo ed ambizioso; tale carattere \\xE8 riscontrabile nel fatto che la proposta dello stesso rappresenta il primo vero tentativo a \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"livello globale\"), \" di \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"regolamentare\"), \" in maniera \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"sistematica\"), \" l\\u2019utilizzo dell\\u2019Intelligenza Artificiale. Rimane ancora da vedere quali modifiche verranno apportate al regolamento nel corso dell\\u2019iter legislativo; ci\\xF2 che \\xE8 certo, per\\xF2, \\xE8 che in questo modo, l\\u2019Unione Europea si conferma come uno dei punti centrali in ambito di regolamentazione di nuove tecnologie digitali.\"), mdx(\"h1\", {\n    \"id\": \"bibliografia\"\n  }, \"Bibliografia\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://www.difesadautore.it\"\n  }, \"www.difesadautore.it\"), mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://www.iusinitinere.it\"\n  }, \"www.iusinitinere.it\"), mdx(\"br\", {\n    parentName: \"p\"\n  }), \"\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://www.agendadigitale.eu\"\n  }, \"www.agendadigitale.eu\"), \"  \"));\n}\n;\nMDXContent.isMDXComponent = true;","tableOfContents":{"items":[{"url":"#aspetti-giuridici","title":"Aspetti Giuridici"},{"url":"#intelligenza-artificiale-forte","title":"Intelligenza Artificiale Forte"},{"url":"#intelligenza-artificiale-debole","title":"Intelligenza Artificiale Debole"},{"url":"#altre-possibili-soluzioni","title":"Altre Possibili Soluzioni"},{"url":"#le-proposte-dellunione-europea","title":"Le Proposte dell'Unione Europea","items":[{"url":"#responsabilità-civile","title":"Responsabilità civile"},{"url":"#obbligo-di-assicurazione","title":"Obbligo di assicurazione"},{"url":"#definizioni","title":"Definizioni"},{"url":"#altri-sistemi-di-ia","title":"Altri sistemi di IA"},{"url":"#risarcimento","title":"Risarcimento"},{"url":"#prescrizione","title":"Prescrizione"}]},{"url":"#la-nuova-proposta-della-commisione-europea","title":"La Nuova Proposta della Commisione Europea","items":[{"url":"#ambiti-di-applicazione","title":"Ambiti di applicazione"},{"url":"#usi-vietati-dellia","title":"Usi vietati dell’IA"},{"url":"#regolamentazione-dei-sistemi-di-ia-ad-alto-rischio","title":"Regolamentazione dei sistemi di IA ad alto rischio"},{"url":"#regole-per-sistemi-ad-alto-rischio","title":"Regole per sistemi ad alto rischio"},{"url":"#regulatory-sandboxes","title":"Regulatory sandboxes"},{"url":"#monitoraggio-dei-sistemi-di-ia","title":"Monitoraggio dei sistemi di IA"},{"url":"#sanzioni","title":"Sanzioni"},{"url":"#conclusioni","title":"Conclusioni"}]},{"url":"#bibliografia","title":"Bibliografia"}]}}},"pageContext":{"slug":"/aspetti-giuridici/"}},"staticQueryHashes":[]}