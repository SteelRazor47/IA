# NON HO VOGLIA

A mio personale giudizio, macchine gestite da software di intelligenza artificiale che, ormai è chiaro, rappresenteranno il futuro, dovrebbero essere sviluppate in modo da ridurre il più possibile il coefficiente di rischio derivante dal loro utilizzo, fino ad avvicinarsi sempre di più ad un probabilmente irraggiungibile rischio zero. Purtroppo queste macchine possono produrre danni notevoli, fino alla morte di una o più persone, come già accaduto più volte, ad esempio, nei vari incidenti che hanno coinvolto macchine Tesla. Per questo motivo, la responsabilità giuridica in tale ambito è un problema da tenere in forte considerazione in quanto, con la sempre maggiore espansione e distribuzione dell’intelligenza artificiale, sarà necessario (in realtà, già lo è) valutare attentamente su chi debba ricadere tale responsabilità.

# DI PENSARE 

È chiaro come un robot, o una qualsiasi macchina dotata di intelligenza artificiale e quindi parzialmente o completamente autonoma, non possa avere personalità giuridica, e non possa quindi assumersi direttamente la responsabilità delle azioni che compie. Questa deve perciò essere necessariamente fatta ricadere su una persona o su un gruppo di persone, ad esempio su chi stava utilizzando la macchina nel momento dell’incidente, su chi ha progettato il software o su chi ha messo in commercio il prodotto. Per una completa e puntuale valutazione del responsabile o dei responsabili di incidenti di qualsiasi tipo ma, in particolare, di quelli che provocano danni a cose o persone, è necessario procedere ad un’attenta e precisa disamina di ogni caso specifico; credo però che, comunque, si possa tentare di dividere i casi, a livello generale, in diverse categorie, che saranno poi differenziate ed assumeranno peculiari caratteristiche in base alle singole situazioni.

# A TITOLI INTELLIGENTI

Per danni causati da malfunzionamenti del software, derivanti ad esempio dalla mancata presa in considerazione di determinate situazioni e quindi da errori in fase di progettazione, da difetti di fabbrica, o dalla mancata segnalazione di situazioni di pericolo in cui la macchina si trovi impossibilitata ad agire, credo sia evidente che la responsabilità sia da attribuire a chi ha progettato il sistema e a chi, senza valutare i possibili rischi, l’ha messo in commercio. Credo sia abbastanza chiaro anche che, nel caso in cui il danno sia stato provocato dalla negligenza nell’impiego della macchina, la colpa sia da addossare a chi la stava utilizzando.
Sono però presenti casi in cui è particolarmente complicato valutare chi sia il vero responsabile di un danno provocato da una macchina.
Uno tra i più complessi, è quello che sta “a metà” tra le due casistiche precedenti, ossia quello in cui la macchina riconosce una situazione di pericolo in cui è impossibilitata ad agire e avvisa l’utilizzatore che però non prende i comandi, come accaduto per l’incidente mortale che ha coinvolto una macchina Tesla ed il suo autista: essa ha avvisato il suo utilizzatore di non poter procedere per via della nebbia, e quest’ultimo non ha preso il comando del veicolo. In questo caso, ritengo sia necessario compiere diverse considerazioni, e quindi valutare se la macchina non fosse in condizione di interrompere la marcia e accostare in condizioni di sicurezza, se il guidatore autonomamente abbia deciso di non prendere i comandi o se sia stato ostacolato da un malore o un colpo di sonno.

# PER CUI TI BECCHI QUESTI

Reputo che, in ogni caso, una parte della colpa sia da attribuire alla casa produttrice: se una macchina non è in grado di procedere, dovrebbe necessariamente riuscire ad arrestarsi in condizioni sicure, in modo da ridurre il rischio derivabile da tale situazione, e preservare la vita del suo utilizzatore, che può essere impossibilitato ad agira, per esempio, per i motivi di cui sopra, e di chiunque si trovi sulla strada. Nel caso di una decisione autonoma e lucida da parte del guidatore, però, credo che l’azienda possa ritenersi almeno in parte assolta dalla responsabilità, anche se ritengo che quest’ultima, prima di mettere in commercio un prodotto, dovrebbe essere sicura del suo funzionamento, soprattutto in situazioni di tale pericolosità.


# POCO SERI

È presente poi un altro caso di labirintica complessità: considerando che, con il passare del tempo e l’avanzare della tecnologia, le macchine dotate di IA sono e saranno sempre più dotate di tecniche apprendimento e quindi sempre più svincolate dalla pura programmazione umana, si svilupperanno sempre più casi in cui il danno sarà causato non più da errori di programmazione o negligenza dell’utilizzatore, ma da comportamenti autonomi e quindi incontrollabili della macchina stessa. Anche in questo caso, ritengo che dovrebbe esserci una drastica riduzione del coefficiente di rischio, andando ad agire sull’algoritmo di apprendimento e testandolo più volte, sia prima di lanciare il prodotto sul mercato, che con controlli periodici dopo il suo acquisto, in modo da tenere costantemente monitorata l’assimilazione dei comportamenti da assumere nelle varie situazioni di pericolo. Se, nonostante questo, la macchina dovesse risultare coinvolta in incidenti derivati da suoi comportamenti scorretti, la colpa ritengo sarebbe da spartire, in differente percentuale a seconda del caso specifico, tra la casa produttrice e l’eventuale revisore: la prima ha messo in commercio il prodotto, senza aver saputo fornire alla macchina un algoritmo grazie al quale fosse in grado di apprendere come comportarsi in una determinata situazione e, il secondo, non ha saputo riconoscere questa falla nel sistema.


# POPI POPI CLOWN FIESTA

Quanto appena presentato, rappresenta un tema particolarmente intricato, delicato e fortemente dibattuto, che ancora non presenta una singola via di risoluzione: quello che è sicuro, però, è che con la sempre più ampia introduzione e diffusione di macchine dotate di intelligenza artificiale, bisognerà arrivare ad accordi stabili, al fine di avere delle solide linee guida da prendere come base nei processi giuridici in quest’ambito, in modo da tutelare al massimo l’incolumità e la vita di chiunque si trovi ad utilizzare tali macchine o, comunque, si trovi in una situazione di pericolo derivante dal possibile comportamento delle stesse. 

