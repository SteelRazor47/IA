---
title: Hello, world!
path: /aspetti-etici
---
# Aspetti Etici

# Una minaccia per l'umanità

Parlando di etica dell’intelligenza artificiale,è facile perdersi in discussioni su futuri distopici: dopotutto, la proliferazione di articoli nei media concernenti le minacce esistenziali che lo sviluppo in questo campo può creare, porta a credere che questo futuro sia dietro l’angolo, e che sia imperativo agire preventivamente poichè, come annunciato da Stephen Hawking, lo sviluppo di una piena intelligenza artificiale può segnare la fine della razza umana.

Ma la verità è che, nonostante non vi sia alcuna colpa nel contemplare i complessi dilemmi etici che potremmo dover affrontare in futuro, tutti questi scenari distopici presumono il raggiungimento di un’**intelligenza artificiale forte (**o **generale) ,** che simuli, o addirittura superi la complessità del pensiero umano, includendo anche la sua sfera emotiva e coscienziale.

Testando le forme di intelligenza superficiale più avanzate attualmente disponibili, si giunge alla conclusione che questo tipo di **superintelligenza** non sarà ancora sviluppata per un lungo tempo: i più ottimisti ipotizzano decenni, ma è impossibile determinare quando e se questo traguardo verrà effettivamente raggiunto, e se mai dovremo affrontare i rischi esistenziali che ne derivano.

L’intelligenza artificiale attualmente sviluppata si classifica come intelligenza artificiale **debole**, o **ristretta:** ciò significa che, in contrapposizione a quella generale, la sua complessità è inferiore a quella dell’intelletto umano, o si limita a simulare una parte limitata di quest’ultimo.

Nonostante questi limiti intrinseci nella sua natura, l’IA a nostra disposizione si è comunque dimostrata capace di fare sorgere questioni e interrogativi sull’etica del suo uso nel quotidiano.


# Benefici apportati dall'IA

L'intelligenza artificiale potrebbe significare una migliore assistenza sanitaria, automobili e altri sistemi di trasporto più sicuri e anche prodotti e servizi su misura, più economici e più resistenti. Può anche facilitare l’accesso all’informazione, all’istruzione e alla formazione. L’IA aiuta a rendere il posto di lavoro più sicuro, offrendo inoltre nuovi posti di lavoro grazie alla crescita delle industrie in questo settore.

L’intelligenza artificiale può consentire lo sviluppo di una nuova
generazione di prodotti e servizi, anche in settori in cui le aziende europee sono già in una posizione di forza.  
Può offrire percorsi di vendita più fluidi e ottimizzati, migliorando la manutenzione dei macchinari, aumentando così sia la quantità che la qualità del prodotto fornito ai clienti.

L’IA applicata ai servizi pubblici può ridurre i costi e offrire nuove opzioni nell’ambito dei trasporti pubblici, dell’istruzione, nonché della gestione dell’energia.


Negli ultimi anni complessi algoritmi sono stati implementati nei processi decisionali in vari settori, con la speranza rendere questi processi più giusti e obiettivi eliminando l’errore umano, e i pregiudizi da cui spesso deriva in questi contesti.  
Così l’IA è stata introdotta :
- nei sistemi giudiziari, come strumento di sostegno nel formulare sentenze;
- nelle aziende, nei processi di assunzione dei dipendenti;
- nei sistemi delle forze dell’ordine, per la profilazione , il riconoscimento e il tracciamento degli individui; 
- nelle banche, per stabilire, ad esempio, a chi concedere finanziamenti;

questi sono solo alcuni esempi di **processo decisionale automatizzato.**


# Rischi e difetti

I numerosi benefici che l’IA apporta in numerosi settori sono purtroppo accompagnati da dubbi e rischi.  
I tre temi dove attualmente i sistemi intelligenti risultano eticamente controversi sono:
- privacy e sicurezza
- discriminazione e pregiudizi sistemici
- l’importanza dell’uomo nei processi decisionali

Il primo include i numerosi dibattiti in corso sul pericolo per la privacy costituito dagli algoritmi che gestiscono i nostri dati personali, come quelli dei social media, e dalla profilazione individuale che ne consegue.

Il secondo e il terzo, spesso collegati, si manifestano concretamente nelle discussioni concernenti i processi decisionali automatizzati che avevamo precedentemente menzionato.  
È giusto affidare a una macchina il futuro di una persona? E soprattutto, siamo sicuri che una macchina sia capace di essere veramente oggettiva nel decidere chi si qualifica per un mutuo, chi verrà rilasciato per buona condotta, o chi si merita una borsa di studio?  
Come affermato dal professore di filosofia politica Michael Sandel ,parte del fascino dei processi decisionali automatizzati è che *sembrano* essere obiettivi, e *pare* superino la soggettività e i pregiudizi umani, e dunque gli errori da essi derivati.  
Ma si sta scoprendo che molti degli algoritmi utilizzati in questi processi sono fondati e replicano i medesimi pregiudizi.  
Ciò è dovuto al fatto che questi algoritmi vengono sviluppati su serie di dati passati, che fungono da “precedente”. Ma se questi dati passati sono macchiati da decadi di pregiudizi sistemici, il nuovo sistema intelligente li ingloberà, e li perpetuerà nelle decisioni che effettuerà in futuro.  
Il rischio, in tutto ciò, è che l’IA commetta gli stessi errori fondati sulla soggettività dell’uomo del passato, ma che questi errori non vengano riconosciuti come tali poiché si associa automaticamente al lavoro dell’algoritmo un valore di oggettività.

Indipendentemente dalla natura del rischio, la consapevolezza nell'industria tecnologica e nella società della potenziale pericolosità dell’intelligenza artificiale è aumentata notevolmente negli ultimi anni, e con questa la necessità da parte di istituzioni, produttori e consumatori di essere consci rispetto ai limiti da imporre e alle libertà da concedere alle nuove tecnologie.

# Regolazione dell'IA da parte dell'UE

Partendo dalla premessa per cui i governi devono garantire l’impiego dell’Intelligenza Artificiale nel massimo rispetto dell’etica, nell’aprile del 2019, l’Unione Europea ha elaborato il suo Codice Etico, che contiene le linee guida su utilizzo e sviluppo di sistemi di Intelligenza Artificiale. Il documento, che è stato predisposto da un gruppo di 52 esperti, rappresentati da informatici, ingegneri ma anche giuristi, filosofi, industriali, matematici, ha avuto un iter lungo e vari fasi di approfondimento.

Il punto di partenza dell’intero documento, e di tutti i principi giuridici che ne sono scaturiti, è che l’Intelligenza Artificiale deve avere l’uomo al centro e deve essere al servizio del bene comune per migliorare il benessere e garantire la libertà. Per prima cosa il gruppo di esperti ha identificato le fondamenta giuridiche sulle quali il codice dovesse poggiare ricercandole nei Trattati UE, nella Carta Dei Diritti e nella legge Internazionale dei Diritti Umani.

Da questa analisi sono stati individuati quei diritti inderogabili che, nell’Unione Europea, devono essere rispettati per l’Intelligenza Artificiale:
- Rispetto per la dignità dell’uomo
- Libertà dell’individuo
- Rispetto per la democrazia e per la giustizia
- Eguaglianza e non discriminazione

Basandosi su questi quattro principi fondamentali su cui si articola il sistema dell’unione europea, sono state stilate le linee guida che definiscono in maniera consona ed inequivocabile il rapporto tra uomo e macchina.
Linee guida:
- Supervisione umana: l’Intelligenza Artificiale deve essere al servizio dell’uomo e non deve invece ridurne, limitarne o fuorviarne l’autonomia, inoltre non devono essere sviluppati sistemi che mettano a rischio i diritti fondamentali dell’uomo. La persona deve restare autonoma e in grado di supervisionare il sistema stesso.
- Solidità tecnica e sicurezza: gli algoritmi devono essere affidabili e sviluppati in	modo tale che la sicurezza non venga messa in pericolo durante l’intero ciclo di vita del sistema.
- Privacy e governance dei dati: i cittadini devono sempre essere informati dell’utilizzo dei propri dati personali nel massimo rispetto della normativa UE sulla privacy per l’intero ciclo di vita del sistema che fa uso dell’Intelligenza Artificiale.
- Trasparenza: trasparenza significa tracciabilità dei sistemi di Intelligenza Artificiale.
- Tutti i dati utilizzati, inclusi gli algoritmi, vanno documentati, solo così si potranno capire i motivi per cui, ad esempio, una decisione basata sull’Intelligenza Artificiale è stata presa in modo errato.
- Diversità, assenza di discriminazione, correttezza: i sistemi di Intelligenza Artificiale devono prendere in considerazione tutte le capacità e le abilità umane, garantendo l’accessibilità a tutti.
- Benessere sociale e ambientale: i sistemi di Intelligenza Artificiale devono essere	utilizzati per sostenere cambiamenti ambientali positivi e perseguire obiettivi di sviluppo sostenibile .
- Responsabilità: devono essere adottati meccanismi di responsabilità nel riportare i dati e gli algoritmi utilizzati nei sistemi di Intelligenza Artificiale. Questo processo di valutazione consente di minimizzare eventuali impatti negativi.

# Conclusioni

Risulta ormai chiaro che per qualsiasi processo cognitivo della mente umana esiste, o esisterà in futuro, una forma di intelligenza artificiale capace di eseguirlo infinitamente meglio. Non ci sono dubbi sul fatto che i sistemi intelligenti somiglieranno sempre più a noi (o a una versione molto meno incapace di noi) fino a che sarà possibile tradurre i nostri pensieri e le nostre azioni in algoritmo.  
Ma lo sviluppo tecnologico, che viaggia ad altissima velocità, già si prepara allo scontro con un muro insormontabile: la dimensione coscienziale umana, la nostra sfera emotiva, irrazionale e spirituale; sono questi aspetti, essenziali all’uomo, che fanno dubitare sarà mai possibile la creazione di un'intelligenza artificiale generale.

Negli ultimi anni è aumentata la consapevolezza del pubblico dell’importanza dell’aspetto etico dell’intelligenza artificiale, perchè abbiamo potuto assistere al sorgere di questioni etiche complesse pure dalle forme di IA attualmente disponibili. E’ dunque naturale preoccuparsi della complessità di tali questioni man mano che la tecnologia progredirà.

La linea d’azione comune che abbiamo potuto osservare nelle regolamentazioni etiche esistenti dei sistemi intelligenti è che sono fortemente antropocentriche. E’ quindi chiaro che, nel contesto di queste norme, l’intelligenza artificiale avrà la libertà di evolversi, ma questa evoluzione sarà sempre subordinata ai valori etici predisposti dall’uomo, ai suoi bisogni e alle sue preoccupazioni.

Questo è perchè l’etica non è una disciplina che la macchina può apprendere: non è traducibile in algoritmo, poiché le sue variabili (ovvero i valori di cui discute) sono estremamente soggettive, in quanto i nostri giudizi di esse sono dettati dalle nostre emozioni e dalla nostra coscienza.   
Come sosteneva il filosofo Bertrand Russell, quando affermiamo che questo o quello ha “valore”, in realtà stiamo conferendo un'espressione alle nostre emozioni, e non a un fatto che prescinde dai nostri sentimenti personali.
Lo stesso filosofo afferma che la nostra percezione di alcuni valori come “buoni” e di altri come “cattivi” è in rapporto con il desiderio dei singoli individui: un valore “buono”,ad esempio, è considerato tale quando è desiderato da un sufficiente numero di persone.  
Dunque l’etica non è altro che “un tentativo di conferire un’importanza universale e non semplicemente personale ad alcuni dei nostri desideri”.

Partendo da questa definizione di etica, si deduce che essa non esista senza desiderio, o emozione. Qualsiasi forma di IA, essendo priva di questi ultimi è intrinsecamente anti-etica, e affinché non si ponga come un pericolo per il benessere umano, è logicamente necessario che venga strettamente controllata e regolata dall’uomo.



# Bibliografia

1. <https://news.harvard.edu/gazette/story/2020/10/ethical-concerns-mount-as-ai-takes-bigger-decision-making-role/>
2. <https://core.ac.uk/download/pdf/301578905.pdf>
3. <https://scipol.duke.edu/news/why-we-are-still-light-years-away-full-artificial-intelligence>
4. <https://it.wikipedia.org/wiki/Intelligenza_artificiale>
5. <https://www.agendadigitale.eu/sicurezza/sicurezza-dellintelligenza-artificiale-tra-vulnerabilita-e-fattore-umano-tutti-i-rischi/>
6. <https://www.europarl.europa.eu/news/it/headlines/society/20200918STO87404/quali-sono-i-rischi-e-i-vantaggi-dell-intelligenza-artificiale>