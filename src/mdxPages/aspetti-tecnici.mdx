---
title: Hello, world!
path: /aspetti-tecnici
---

# AI

In termini tecnici, l'Intelligenza Artificiale è un ramo dell'informatica che permette la programmazione e progettazione di sistemi sia hardware che software che permettono di dotare le macchine di determinate caratteristiche che vengono considerate tipicamente umane quali, ad esempio, le percezioni visive, spazio-temporali e decisionali. Si tratta cioè, non solo di intelligenza intesa come capacità di calcolo o di conoscenza di dati astratti, ma anche e soprattutto di tutte quelle differenti forme di intelligenza che sono riconosciute dalla teoria di Gardner, e che vanno dall'intelligenza spaziale a quella sociale, da quella cinestetica a quella introspettiva. Un sistema intelligente, infatti, viene realizzato cercando di ricreare una o più di queste differenti forme di intelligenza che, anche se spesso definite come semplicemente umane, in realtà possono essere ricondotte a particolari comportamenti riproducibili da alcune macchine.

Alla base delle problematiche legate allo sviluppo di sistemi e programmi di Intelligenza Artificiale vi sono tre parametri che rappresentano i cardini del comportamento umano, ossia una conoscenza non sterile, una coscienza che permetta di prendere decisioni non solo secondo la logica e l'abilità di risolvere problemi in maniera differente anche a seconda dei contesti nei quali ci si trova.

L'uso delle reti neurali e di algoritmi in grado di riprodurre ragionamenti tipici degli esseri umani nelle differenti situazioni, hanno permesso ai sistemi intelligenti di migliorare sempre di più le diverse capacità di comportamento. Per poter realizzare ciò, la ricerca si è concentrata non solo sullo sviluppo di algoritmi sempre nuovi, ma soprattutto su algoritmi sempre più numerosi, che potessero imitare i diversi comportamenti a seconda degli stimoli ambientali. Tali algoritmi complessi, inseriti all'interno di sistemi intelligenti, sono quindi in grado di 'prendere decisioni' ossia di effettuare scelte a seconda dei contesti in cui sono inseriti. Nel caso degli algoritmi connessi ai sistemi intelligenti dei veicoli, ad esempio, un'automobile senza conducente può decidere, in caso di pericolo, se sterzare o frenare a seconda della situazione, ossia a seconda che le informazioni inviate dai vari sensori permettano di calcolare una maggiore percentuale di sicurezza per il conducente e i passeggeri con una frenata o con una sterzata.

# Machine learning

Le decisioni di ogni tipo, sia quelle prese da un'auto senza pilota che da altri sistemi di Intelligenza Artificiale, sono prese, come già specificato, grazie alla realizzazione di determinati algoritmi, che permettono di definire una conoscenza di base e una conoscenza allargata, ossia creata tramite l'esperienza. Per realizzare algoritmi sempre più precisi e complessi, è sorta un vero e proprio settore specifico, definito rappresentazione della conoscenza, che studia tutte le possibilità di ragionamento dell'uomo e, soprattutto, tutte le possibilità di rendere tale conoscenza comprensibile alle macchine tramite un linguaggio e dei comandi sempre più precisi e dettagliati. Quando si parla di conoscenza dell'uomo e di trasferimento di tale conoscenza alla macchina, infatti, non si parla solo di conoscenza sterile, ossia di nozioni apprese dai libri o da altri strumenti di studio. Si parla piuttosto di esperienza e di possibilità di comprendere nuove informazioni tramite quelle già presenti nel sistema di partenza. Tali informazioni vengono fornite alla macchina tramite diverse modalità, le più importanti delle quali sono quelle che si basano sulla Teoria dei Linguaggi Formali e sulla Teoria delle Decisioni.

Nel primo caso, quando cioè si utilizza la Teoria dei Linguaggi Formali, si sceglie di utilizzare diversi approcci (quelli riconosciuti sono l'approccio generativo, riconoscitivo, denotazionale, algebrico e trasformazionale) che si rifanno alle teorie delle Stringhe e ai loro utilizzi. Le stringhe, infatti, rappresentano dei veri e propri linguaggi formali le cui proprietà variano proprio a seconda dell'approccio utilizzato. Si può quindi decidere di puntare su un approccio o sull'altro a seconda dei risultati che si intende ottenere, ossia a seconda del tipo di risposta che si vuole ottenere dalla macchina nelle differenti situazioni.

Albero di decisione nell'Intelligenza Artificiale. La Teoria delle Decisioni, invece, si basa su un albero di decisione, che permette di valutare per ogni azione/decisione le possibili conseguenze prendendo quindi poi la decisione più conveniente. A seconda delle impostazioni e dello scopo del programma, quindi, il sistema potrà prendere la decisione che meglio ottimizza il risultato che si vuole ottenere. Va sottolineato che situazioni simili possono prevedere risultati differenti a seconda del tipo di piano di azioni definito dagli algoritmi della macchina.

L'utilizzo della Teoria delle Decisioni e degli alberi di decisione merita un maggiore approfondimento, perché maggiormente sfruttata soprattutto in tutti quei sistemi intelligenti utilizzati nel quotidiano. Come funzione un albero di decisione? Senza entrare nel dettaglio, basta sapere che un albero di decisione si basa su modelli predittivi a partire da una serie di informazioni iniziali e dati di partenza. Tali dati possono poi essere suddivisi in maniera tale da definire sia la struttura, ossia il tipo di previsioni possibili, sia l'accuratezza delle stesse. Proprio l'accuratezza dei dati permette di ottenere dei sistemi intelligenti che si differenziano tra di loro per le risposte in grado di dare a seconda non tanto del numero di dati sul quale si basano le decisioni, ma a seconda della precisione degli stessi. Va sottolineato, inoltre, che la mole di dati a disposizione per le elaborazioni delle Intelligenze Artificiali può interferire con la precisione del modello utilizzato. Per questo motivo i modelli più accurati presentano un numero di informazioni di partenza spesso inferiore a quello che si può immaginare: la bontà del modello viene comunque assicurata dalla dal tipo di dati di partenza e dall'accuratezza degli stessi.

Uno dei principali passi avanti nella storia dell'Intelligenza Artificiale è stata fatta quando si sono potuti ricreare degli algoritmi specifici, in grado di far migliorare il comportamento della macchina (inteso come capacità di agire e prendere decisioni) che può così imparare tramite l'esperienza, proprio come gli esseri umani. Sviluppare algoritmi in grado di imparare dai propri errori è fondamentale per realizzare sistemi intelligenti che operano in contesti per i quali i programmatori non possono a priori prevedere tutte le possibilità di sviluppo e i contesti in cui il sistema si trova a operare. Tramite l'apprendimento automatico (machine learning), quindi, una macchina è in grado di imparare a svolgere una determinata azione anche se tale azione non è mai stata programmata tra le azioni possibili.

Per i non addetti ai lavori, probabilmente l'apprendimento automatico rappresenta la parte più 'romantica' dell'Intelligenza Artificiale, quella su cui diversi registi hanno saputo trarre interessanti spunti per i loro film più o meno noti che vedono macchine e robot migliorarsi nel tempo proprio perché in grado di imparare tramite l'esperienza. Al di là dell'interesse scenico e romanzesco che può avere l'apprendimento automatico, dietro di questo particolare ramo dell'Intelligenza Artificiale vi è stata da sempre (e vi è ancora) una profonda ricerca, sia teorica che pratica, basata, tra le altre cose, sulla teoria computazionale dell'apprendimento e sul riconoscimento dei pattern. La complessità dell'apprendimento automatico ha portato a dover suddividere tre differenti possibilità, a seconda delle richieste di apprendimento che vengono fatte alla macchina. Si parla allora di apprendimento supervisionato, di apprendimento non supervisionato e di apprendimento per rinforzo. La differenza tra le tre modalità sta soprattutto nel differente contesto entro cui si deve muovere la macchina per apprendere le regole generali e particolari che lo portano alla conoscenza. Nell'apprendimento supervisionato, in particolare, alla macchina vengono forniti degli esempi di obiettivi da raggiungere, mostrando le relazioni tra input, output, e risultato. Dall'insieme dei dati mostrati, la macchina deve essere in grado di estrapolare una regola generale, che possa permettere, ogni volta che venga stimolata con un determinato input, di scegliere l'output corretto per il raggiungimento dell'obiettivo.

Nel caso di apprendimento non supervisionato, invece, la macchina dovrà essere in grado di effettuare scelte senza essere stato prima 'educato' alle differenti possibilità di output a seconda degli input selezionati. In questo caso, quindi, il computer non ha un maestro che gli permetta un apprendimento ma impara esclusivamente dai propri errori. Infine, le macchine che vengono istruite tramite un apprendimento per rinforzo si trovano ad avere un'interazione con un ambiente nel quale le caratteristiche sono variabili. Si tratta, quindi, di un ambiente dinamico, all'interno del quale la macchina dovrà muoversi per portare a termine un obiettivo non avendo nessun tipo di indicazione se non, alla conclusione della prova, la possibilità di sapere se è riuscita o meno a raggiungere lo scopo iniziale.

L'apprendimento automatico è stato reso possibile dallo sviluppo delle reti neurali artificiali, ossia un particolare modello matematico che, ispirandosi ai neuroni e alle reti neurali umane, punta alla soluzione dei diversi problemi a seconda delle possibilità di conoscere gli input e i risultati ottenuti a seconda delle scelte effettuate. Il nome di rete neurale deriva dal fatto che questo modello matematico è caratterizzato da una serie di interconnessioni tra tutte le diverse informazioni necessarie per i diversi calcoli. Inoltre, proprio come le reti neurali biologiche, anche una rete neurale artificiale ha la caratteristica di essere adattativa, ossia di saper variare la sua struttura adattandola alle specifiche necessità derivanti dalle diverse informazioni ottenute nelle diverse fasi di apprendimento. Dal punto di vista matematico, una rete neurale può essere definita come una funzione composta, ossia dipendente da altre funzioni a loro volta definibili in maniera differente a seconda di ulteriori funzioni dalle quali esse dipendono. Questo significa che nulla, all'interno di una rete neurale, può essere lasciato al caso: ogni azione del sistema intelligente sarà sempre il risultato dell'elaborazione di calcoli volti a verificare i parametri e a definire le incognite che definiscono le funzioni stesse.

# Deep learning

La traduzione strettamente letterale di questo termine, di chiara matrice anglosassone, è apprendimento approfondito. Ed è proprio questo il centro del suo significato, perché il deep learning, sottocategoria del Machine Learning, non fa altro che creare modelli di apprendimento su più livelli. Il concetto è molto semplice. Immaginiamo di esporre una nozione. La apprendiamo e subito dopo ne esponiamo un'altra. Il nostro cervello raccoglie l'input della prima e la elabora insieme alla seconda, trasformandola e astraendola sempre di più. Scientificamente, è corretto definire l'azione del deep learning come l'apprendimento di dati che non sono forniti dall'uomo, ma sono appresi grazie all'utilizzo di algoritmi di calcolo statistico. Questi algoritmi hanno uno scopo: comprendere il funzionamento del cervello umano e come riesca ad interpretare le immagini e linguaggio. L'apprendimento così realizzato ha la forma di una piramide: i concetti più alti sono appresi a partire dai livelli più bassi.

Il deep learning ha compiuto passi da gigante, ottenendo risultati che, fino a qualche decennio fa, erano pura utopia. Tale successo è dovuto alle numerose conquiste in campo informatico, relative soprattutto alla sfera dell'hardware. Abbiamo visto come sia importante portare il calcolatore a fare esperienza su un quantitativo sempre maggiore di dati sensibili e come, fino a poco tempo fa, il tempo per ottenere tale addestramento fosse abbastanza elevato. Oggi, grazie all'introduzione delle GPUs, ovvero nuove unità che concorrono all'elaborazione dati, questo processo è diventato molto più snello. Un altro importante aiuto è derivato dalla facilità di trovare numerose collezioni di dati (dataset) fondamentali per allenare il sistema. Il deep learning fa una cosa fondamentale: ci regala la rappresentazione dei dati, ma lo fa a livello gerarchico e soprattutto a livelli diversi tra loro, riuscendo a elaborarli e a trasformarli. Questa trasformazione è stupefacente perché ci consente di assistere ad una macchina che riesce a classificare i dati in entrata (input) e quelli in uscita (output), evidenziando quelli importanti ai fini della risoluzione del problema e scartando quelli che non servono. La rivoluzione apportata dal deep learning è tutta nella capacità, simile a quella umana, di elaborare i dati, le proprie conoscenze a livelli che non sono affatto lineari. Grazie a questa facoltà, la macchina apprende e perfeziona funzionalità sempre più complesse.

Per comprendere il raggio d'azione del deep learning occorre chiarire un concetto fondamentale ovvero quello relativo alle reti neurali. Immaginiamo un comando vocale. La stessa parola, ripetuta da persone diverse, può avere sfumature e inflessioni che cambiano in base all'individuo che la pronuncia. Come fa il PC a riconoscere il suono, a identificarlo? È ovvio che, da un punto di vista strettamente scientifico, un algoritmo sequenziale non può fornire il giusto supporto.

# Reti neurali

I circuiti neurali artificiali sono la base di sofisticate forme di intelligenza artificiale, sempre più evolute, in grado di apprendere sfruttando meccanismi simili (almeno in parte) a quelli dell'intelligenza umana. Risultato: prestazioni impossibili per altri algoritmi.

Il prototipo delle reti neurali artificiali sono quelle biologiche.

Le reti neurali del cervello umano sono la sede della nostra capacità di comprendere l'ambiente e i suoi mutamenti, e di fornire quindi risposte adattive calibrate sulle esigenze che si presentano.

Sono costituite da insiemi di cellule nervose fittamente interconnesse fra loro. Al loro interno troviamo:

- i somi neuronali, ossia i corpi dei neuroni. Ricevono e processano le informazioni; in caso il potenziale di azione in ingresso superi un certo valore, generano a loro volta degli impulsi in grado di propagarsi nella rete;
- i neurotrasmettitori, composti biologici di diverse categorie (ammine, peptidi, aminoacidi), sintetizzati nei somi e responsabili della modulazione degli impulsi nervosi;
- gli assoni o neuriti: la via di comunicazione in uscita da un neurone. Ogni cellula nervosa ne possiede di norma soltanto uno;
- i dendriti: la principale via di comunicazione in ingresso; sono multipli per ogni neurone, formando il cosiddetto albero dendritico;
- le sinapsi, o giunzioni sinaptiche: i siti funzionali ad alta specializzazione nei quali avviene il passaggio delle informazioni fra neuroni. Ognuno di questi ne possiede migliaia. A seconda dell'azione esercitata dai neurotrasmettitori, le sinapsi hanno una funzione eccitatoria, facilitando la trasmissione dell'impulso nervoso, oppure inibitoria, tendente a smorzarlo. Le connessioni hanno luogo quando il neurotrasmettitore viene rilasciato nello spazio intersinaptico, raggiungendo così i recettori delle membrane post-sinaptiche (ossia del neurone successivo), e, alterandone la permeabilità, trasmettendo l'impulso nervoso.

Un singolo neurone può ricevere simultaneamente segnali da diverse sinapsi. Una sua capacità intrinseca è quella di misurare il potenziale elettrico di tali segnali in modo globale, stabilendo quindi se è stata raggiunta la soglia di attivazione per generare a sua volta un impulso nervoso. Tale proprietà è implementata anche nelle reti artificiali.

La configurazione sinaptica all'interno di ogni rete neurale biologica è dinamica. Si tratta di un fattore determinante per la loro efficienza. Il numero di sinapsi può incrementare o diminuire a seconda degli stimoli che riceve la rete. Più sono numerosi, maggiori connessioni sinaptiche vengono create, e viceversa. In questo modo, la risposta adattiva fornita dai circuiti neurali è più calibrata, e anche questa è una peculiarità implementata nelle reti neurali artificiali.

Nelle reti artificiali ovviamente il processo di apprendimento automatico è semplificato rispetto a quello delle reti biologiche. Non esistono analoghi dei neurotrasmettitori, ma lo schema di funzionamento è simile.

I nodi ricevono dati in input, li processano e sono in grado di inviare le informazioni ad altri neuroni. Attraverso cicli più o meno numerosi di input-elaborazione-output, in cui gli input presentano variabili differenti, diventano in grado di generalizzare e fornire output corretti associati ad input non facenti parte del training set.

Gli algoritmi di apprendimento utilizzati per istruire le reti neurali sono divisi in 3 categorie. La scelta di quale usare dipende dal campo di applicazione per cui la rete è progettata e dalla sua tipologia (feedforward o feedback).

Gli algoritmi si rifanno ai classici algoritmi di machine learning precedentemente presentati e sono:

- supervisionato;
- non supervisionato;
- di rinforzo.

# Apprendimento Supervisionato (Reti neurali)

Nell'apprendimento supervisionato si fornisce alla rete un insieme di input ai quali corrispondono output noti (training set). Analizzandoli, la rete apprende il nesso che li unisce. In tal modo impara a generalizzare, ossia a calcolare nuove associazioni corrette input-output processando input esterni al training set.

Man mano che la macchina elabora output, si procede a correggerla per migliorarne le risposte variando i pesi. Ovviamente, aumentano i pesi che determinano gli output corretti e diminuiscono quelli che generano valori non validi.

Il meccanismo di apprendimento supervisionato impiega quindi l'Error Back-Propagation, ma è molto importante l'esperienza dell'operatore che istruisce la rete.

Il motivo risiede nel non facile compito di trovare un rapporto adeguato fra le dimensioni del training set, quelle della rete e l'abilità a generalizzare che si tenta di ottenere.

Un numero eccessivo di parametri in ingresso e una troppo potente capacità di elaborazione, paradossalmente, rendono difficile alla rete neurale imparare a generalizzare, perché gli input esterni al training set vengono valutati dalla rete come troppo dissimili ai sofisticati e dettagliati modelli che conosce.

D'altro canto, un training set con variabili scarse porta per la via opposta alla stessa conclusione: la rete, in questo caso, non ha sufficienti parametri per apprendere a generalizzare.

Il giusto compromesso, insomma, è un compito che necessita di molta preparazione ed esperienza.

Le reti feedforward come il MLP utilizzano l'apprendimento supervisionato.

# Apprendimento non supervisionato (Reti neurali)

In una rete neurale ad apprendimento non supervisionato, la medesima riceve solo un insieme di variabili di input. Analizzandole, la rete deve creare dei cluster rappresentativi per categorizzarle. Anche in questo caso i valori dei pesi sono dinamici, ma sono i nodi stessi a modificarli.

Esempi di reti ad apprendimento supervisionato sono SOM e la rete di Hopfield.

# Apprendimento per rinforzo (Reti neurali)

Nelle reti neurali che apprendono mediante l'algoritmo di rinforzo, non esistono né associazioni input-output di esempi, né un aggiustamento esplicito degli output da ottimizzare.

I circuiti neurali imparano esclusivamente dall'interazione con l'ambiente. Su di esso, eseguono una serie di azioni.

Dato un risultato da ottenere, è considerato rinforzo l'azione che avvicina al risultato; viceversa, la rete apprende a eliminare le azioni negative, ossia foriere di errore.

Detto in altri termini, un algoritmo di apprendimento per rinforzo mira a indirizzare la rete neurale verso il risultato sperato con una politica di incentivi (azioni positive) e disincentivi (azioni negative).

Usando tale algoritmo, una macchina impara a trovare soluzioni che non è esagerato definire creative. Una rete neurale così implementata, per esempio, è stata utilizzata per giocare ad Arcade Breakout. Risultato: dopo sole quattro ore di continuo miglioramento, i circuiti hanno individuato una strategia di gioco mai ideata da un essere umano in questo videogame.

# Vantaggi delle reti neurali

L'utilizzo delle varie tipologie di reti neurali nasce dagli importanti vantaggi che presentano:

- elevato parallelismo, grazie al quale possono processare in tempi relativamente rapidi grandi moli di dati;
- tolleranza ai guasti, anche questo grazie all'architettura parallela;
- tolleranza al rumore, ossia la capacità di operare, in molti casi, in modo corretto nonostante input imprecisi o incompleti;
- in alcune categorie di problemi costituiscono lo strumento migliore per gestirlo. Data mining, optimization, elaborazione di modelli predittivi e simulativi e classificazione sono i campi di impiego preferenziali per le reti neurali;
- evoluzione adattiva: una rete neurale ben implementata è in grado di autoaggiornarsi in presenza di modifiche ambientali.

# Limiti

Le reti neurali artificiali hanno comunque dei limiti, ed è difficile prevedere se col tempo potranno essere eliminati o attenuati.

I più importanti sono:

- funzionamento a black box. Un handicap rimarchevole delle reti neurali artificiali è il fatto che la loro computazione non è analizzabile in modo completo. Con questo si intende dire che sono in grado di fornire output corretti, o sufficientemente corretti, ma non permettono di esaminare i singoli stadi di elaborazione che li determinano;
- non è possibile avere la certezza a priori che un problema sarà risolto;
- gli output forniti spesso non rappresentano la soluzione perfetta, anche se in molti casi questo non è necessario;
- il periodo di learning è più o meno lungo. Le iterazioni necessarie dipendono da fattori quali numero e complessità delle variabili di input, algoritmo utilizzato, etc. In realtà, in tale ambito sono stati fatti importanti progressi, ed è ragionevole ipotizzare che in futuro il periodo di learning potrà ulteriormente ridursi;
- le reti neurali non sono idonee a risolvere determinate categorie di problemi. Un esempio è un tipo di input costituito da un numero elevato di variabili categoriche.